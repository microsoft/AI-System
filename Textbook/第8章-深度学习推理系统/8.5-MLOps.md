<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 8.5 MLOps

MLOps 是一种用于人工智能(包含机器学习与深度学习)工程的方法，它将机器学习（例如，模型的训练与推理）开发与机器学习系统（深度学习框架，自动化机器学习系统）统一起来操作与维护（Ops部分）。MLOps的过程希望标准化和自动化机器学习全生命周期的关键步骤。MLOps 提供了一套标准化的流程和工具，用于构建、部署、快速可靠地运行机器学习全流程和机器学习系统。相比于传统的DevOps不同之处在于，当用户部署Web服务时，用户关心的是每秒查询数(QPS)、负载平衡(Load Balance)等。在部署机器学习模型时，用户还需要关注数据的变化、模型的变化等。这些是MLOps所要解决的新的挑战。 

[TOC]

## 8.5.1 MLOps的生命周期

推理系统本身就像传统Web服务发布代码包一样，需要定期发布模型，提供新功能或更好的效果。
这些挑战类似于应用程序开发团队在创建和管理应用程序时面临的挑战。借鉴传统的软件工程最佳实践，业界使用了DevOps，这是管理应用程序开发周期操作的行业标准。为了应对深度学习全生命周期的挑战，组织需要一种将 DevOps 的敏捷性带入ML 生命周期的方法，业界称这种方法为[MLOps](https://docs.microsoft.com/en-us/learn/modules/start-ml-lifecycle-mlops/2-mlops-introduction)

<center> <img src="./img/4/8-4-5-mlops.png" width="500" height="300" /></center>
<center>图8-4-2. 模型构建与部署 </center>

接下来，我们以其中的代表性的问题进行介绍。

## 8.5.2 机器学习与深度学习模型管理

在MLOps中，其中较为关键的是模型的版本管理：线上发布，回滚等策略。因为近些年，软件逐渐由客户端软件演化为在线部署的服务，而模型最终也是部署于一定的软件系统中，所以越来越多的模型部署于在线服务中(online service)。在在线服务中， 每隔一段时间训练出的新版本模型替换线上模型，但是可能存在缺陷，另外如果新版本模型发现缺陷需要回滚。同时在整个模型的生命周期中，还有很多代表性的服务，工具和系统也越来越充当着非常重要的角色。

- ***模型动物园(model zoo)***
Model Zoo是开源框架和公司组织机器学习和深度学习模型的常用方式。当前很多场景下由于使用预训练模型可以大幅减少训练代价，或者很多开发者没有足够资源从头训练造成集成预训练模型并进行微调的方式。例如，[Hugging Face](https://huggingface.co/)就通过语言模型的Model Zoo不断拓展社区，并形成语言模型场景应用广泛的工具:
- ***模型转换***
由于框架之间互用预训练模型以及训练到部署的运行时环境不同，产生了模型转换的需求，这其中[MMdnn](https://github.com/microsoft/MMdnn)和[ONNX](https://onnx.ai/)为代表的工具正是为解决这个需求而产生。
- ***模型验证***
模型本身容易产生各种类型错误，有相关工作如[REFTY](https://www.microsoft.com/en-us/research/publication/refty-refinement-types-for-valid-deep-learning-models/), [Pythia](https://github.com/plast-lab/doop-mirror/blob/master/docs/pythia.md)等通过静态检测的方式在训练前提前验证和规避相应的错误，保证模型的结构正确性。
- ***模型调试器***
由于模型训练过程中，无论研究工作还是实际工作中充满了大量的技巧(trick)，对于小白用户希望像专家一下进行模型的训练优化保证交付模型，为了应对这种需求，一些工具和云服务提供模型和训练过程的调试，这样让即使没有相关经验的用户也能训练出效果好的模型。
- ***特征分布监测***
由于很多实际场景中，数据不断的增长，造成原有的数据分布产生了变化，而人工智能模型又对数据分布的变化较为敏感，所以不断监测数据分布变化，并在一定条件下触发模型重新训练，也是整个生命周期中非常重要的环节。
- ***模型版本管理***
由于模型上线使用后并不是一劳永逸，随着数据分布变化，或算法工程师设计新的模型效果更好，需要不断上线新模型替代原有模型，这就要求当前的推理系统，或模型部署的服务器文件系统或者网络文件系统做好相应的模型版本管理和策略，方便模型更新与回滚。


## 8.5.3 线上发布与回滚策略

A/B测试：A/B 测试是一种优化技术，通常用于了解更改的变量如何影响受众或用户参与度。这是营销、网页设计、产品开发和用户体验设计中用于提高活动和目标转化率的常用方法。A/B测试一般采用对用户流量进行分桶，即将其分成实验组和对照组用户，对实验组的用户部署新模型返回请求应答，对照组的用户沿用旧模型，在分桶的过程中，需要注意样本的独立性和无偏性，保证用户每次只能分到同一个桶中，最终验证新模型和旧模型的效果优势，如果有优势可以上线新模型。总结起来，对需要在线部署的模型，A/B测试有以下的好处和作用：1. 离线评估无法完全消除过拟合的影响。2. 离线评估无法完全还原线上的工程环境。例如，数据延迟、缺失等情况。3. 线上系统的某些评测指标在离线评估中无法计算。

模型生命周期管理的具体策略实例还有有：[金丝雀(canary)策略，回滚(rollback)策略](https://arxiv.org/pdf/1712.06139.pdf)。
- 金丝雀策略
  - 当获得一个新训练的模型版本时，当前服务的模型成为第二新版本时，用户可以选择同时保持这两个版本
  - 将所有推理请求流量发送到当前两个版本，比较它们的效果
  - 一旦对最新版本达标，用户就可以切换到仅使用最新版本
  - 该策略需要更多的高峰资源，避免将用户暴露于缺陷模型
- 回滚策略
  - 如果在当前的主要服务版本上检测到缺陷，则用户可以请求切换到特定的较旧版本
  - 卸载和装载的顺序应该是可配置的
  - 当问题解决并且获取到新的安全版本模型时，从而结束回滚

当然业界每家公司也会根据自身在线服务特点设计和定制个性化的策略和线上管理流程，其目标都是朝着敏捷不断迭代模型，可回滚，可靠等角度去设计和迭代优化的。

## 8.6.4 代表性MLOps工具与服务

- [MLflow](https://mlflow.org/)：是由UCB开源的MLOps工具，其提供标准化的API，Python社区友好，并让MLOps概念深入人心。
- [Amazon SageMaker MLOps](https://aws.amazon.com/sagemaker/mlops/)：此服务为亚马逊云服务机器学习平台SageMaker提供的MLOps服务，其提供全流程的机器学习声明周期管理，并提供特色的模型调试与诊断功能，将专家级调试经验自动化。
- [Azure Machine Learning](https://azure.microsoft.com/en-us/services/machine-learning/mlops/)：微软Azure Machine Learning服务也提供了MLOps的功能，并持续构建全套解决方法，与微软云集成度最佳。
- [Google Cloud MLOps](https://cloud.google.com/resources/mlops-whitepaper)：Google Cloud的MLOps功能不仅较早提出，同时向业界发布白皮书，布道相关概念与技术。

## 参考文献

- [Park, Jongsoo et al. “Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications.” ArXiv abs/1811.09886 (2018): n. pag.](https://arxiv.org/abs/1811.09886)
- [Crankshaw, Daniel et al. “Clipper: A Low-Latency Online Prediction Serving System.” NSDI (2017).](https://www.usenix.org/system/files/conference/nsdi17/nsdi17-crankshaw.pdf)
- [Denis Baylor, Eric Breck, Heng-Tze Cheng, Noah Fiedel, Chuan Yu Foo, Zakaria Haque, Salem Haykal, Mustafa Ispir, Vihan Jain, Levent Koc, Chiu Yuen Koo, Lukasz Lew, Clemens Mewald, Akshay Naresh Modi, Neoklis Polyzotis, Sukriti Ramesh, Sudip Roy, Steven Euijong Whang, Martin Wicke, Jarek Wilkiewicz, Xin Zhang, and Martin Zinkevich. 2017. TFX: A TensorFlow-Based Production-Scale Machine Learning Platform. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD '17). Association for Computing Machinery, New York, NY, USA, 1387–1395. DOI:https://doi.org/10.1145/3097983.3098021](https://research.google/pubs/pub46484/)
- [Olston, Christopher et al. “TensorFlow-Serving: Flexible, High-Performance ML Serving.” ArXiv abs/1712.06139 (2017): n. pag.](https://arxiv.org/abs/1712.06139)
- https://www.microsoft.com/en-us/research/project/ai-tooling-and-mlops/
- https://zhuanlan.zhihu.com/p/59685112
- ttps://docs.microsoft.com/en-us/learn/modules/start-ml-lifecycle-mlops/2-mlops-introduction
- https://aws.amazon.com/sagemaker/mlops/
- https://azure.microsoft.com/en-us/services/machine-learning/mlops/
- https://cloud.google.com/resources/mlops-whitepaper