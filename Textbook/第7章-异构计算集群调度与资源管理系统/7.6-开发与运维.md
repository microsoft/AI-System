<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 7.6 开发与运维

在之前的章节，我们已经介绍面向深度学习的集群管理系统的运行时与调度。本章将围绕工程实践中，关于集群管理系统开发，运维的话题进行展开。集群管理系统，也称作平台，是7x24小时的对公司内部使用或者对外提供服务的平台型服务，其本身的开发越来越敏捷，同时也需要有更加敏捷而高效的运维支持。本章将围绕开发与运维的整体内容展开。


- [7.6 开发与运维](#76-开发与运维)
  - [7.6.1 平台功能模块与敏捷开发](#761-平台功能模块与敏捷开发)
  - [7.6.2 监控体系构建](#762-监控体系构建)
      - [***全局监控***](#全局监控)
      - [***性能监控***](#性能监控)
      - [***服务与硬件稳定性监控***](#服务与硬件稳定性监控)
      - [***报警***](#报警)
  - [7.6.3 测试](#763-测试)
      - [***单元测试***](#单元测试)
      - [***集成测试***](#集成测试)
      - [***压力测试***](#压力测试)
      - [***回归测试***](#回归测试)
      - [***模糊测试(Fuzzing)与混沌工程***](#模糊测试fuzzing与混沌工程)
  - [7.6.4 平台部署与DevOps](#764-平台部署与devops)
  - [7.6.5 平台运维](#765-平台运维)
      - [***直接责任人（DRI）与候命（On-Call）机制***](#直接责任人dri与候命on-call机制)
      - [***事件管理***](#事件管理)
      - [***智能运维***](#智能运维)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)
  
## 7.6.1 平台功能模块与敏捷开发

平台本身由于功能众多，整体性质属于在线服务，业界一般通过敏捷开发的模式进行整体的开发与设计。一般平台中涉及以下重要服务和功能模块的开发与设计。

- 内核：调度器，运行时，管理GUI，权限管理，文件管理等。
  - 调度器设计可以兼顾深度学习特点例如资源局部性。
  - 运行时需要支持特定设备插件，能够将GPU，IB等设备注册进入运行时。
  - 由于深度学习作业主要输入输出为数据和模型，一般可使用文件系统存储即可，需要选用高效（NFS等）且容错（云存储）的文件系统提供支持。
- 监控与报警：性能监控，异常监控，报警系统等。
  - 除常见需要平台监控的性能指标，还要特别关注GPU等核心加速器的资源利用率等指标。
  - 报警系统也要除覆盖常见错误，还需要覆盖新服务与新硬件产生的错误与异常。
- 工具链：IDE，作业提交与调试工具，API(例如：Restful)等。
  - IDE可以选用对Python和深度学习生态支持较好的开发环境。例如，基于浏览器的开发工具(Jupyter)或者插件化支持较好的本地客户端环境VS Code等。
  - 作业提交可以通过Web人工提交或者Restful API方便AutoML工具自动化提交。
  - 可以考虑支持远程SSH方便用户远程登录作业现场调试
- 应用市场：模型市场，镜像市场等。
  - 由于目前深度学习新的模型很多基于研究工作和开源模型与代码进行微调适配和扩展，模型训练框架主流框架也都是开源的，这就让平台方可以通过提供常用和优化版本的模型与框架镜像市场进而优化，管理和提升开发生产力。

不同的功能模块可以分配不同的工程师进行开发，通过[Scrum](https://en.wikipedia.org/wiki/Scrum_(software_development))敏捷开发机制，指定Sprint计划，并通过每日的Scrum进行规划反思与推进。

## 7.6.2 监控体系构建

通过构建完整的指标体系，能够让平台管理员和开发者对平台健康状况和系统负载运行状况一目了然，同时有助于对异常与错误进行诊断与归因分析。围绕异构资源管理系统，可以从以下方面设计指标， 进而通过数据驱动的方法提升运维效率。

#### ***全局监控***

可以通过围绕作业，服务，节点几个维度设计需要整体宏观监控的指标，并围绕团队的核心KPI设计效率，稳定性等全局指标，方便回查与评估。

<center> <img src="./img/6/7-6-1-monitorpage.jpg" ch="500" width="800" height="600" /></center>
<center>图7-6-1. 平台全局监控(<a href="https://github.com/microsoft/pai">图片来源</a>)</center>

如图所示，平台可以通过全局监控观测硬件资源的利用率，健康状况，也可以拓展到作业，用户等其他指标。通过宏观监控让管理员和运维工程师能观测重要问题，对整体有宏观认识。

#### ***性能监控***

可以围绕作业和硬件的性能进行监控设计，其中硬件的各种指标在作业执行时间的连接可以推导出作业的性能指标。对深度学习系统，尤其需要关注GPU的利用率等指标，这可以通过[NVML](https://developer.nvidia.com/nvidia-management-library-nvml)，[DCGM](https://developer.nvidia.com/dcgm)等工具构建指标导出器进行监控与获取。

例如，我们可以通过nvidia-smi命令获取GPU的利用率，显存使用状况，温度和功耗，以及是否有ECC error等信息，进而将这些信息暴露给监控系统收集，进而形成对系统性能和健康的持续监控。

```shell
$ nvidia-smi
...
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.23.05    Driver Version: 455.23.05    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00004F2F:00:00.0 Off |                    0 |
| N/A   51C    P0    56W / 149W |   2513MiB / 11441MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00007C52:00:00.0 Off |                    0 |
| N/A   31C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

```
#### ***服务与硬件稳定性监控***

可以观测和监控平台的各个模块的健康，通过被动汇报或者主动探测的机制，监测服务的存活状况。对硬件可以周期性运行测试，或者通过监控指标的异常进行判断。服务模块在设计之初就需要考虑暴露接口或者心跳机制设计，可以被监控系统更好的遥测。

很多平台和服务提供了服务存活检测的机制，让服务开发者在服务设计之初就考虑好系统健康状况的可观测性。

例如，以Kubernetes为例，许多长时间运行的应用程序最终会转变为损坏状态，除非重新启动，否则无法恢复。 Kubernetes 提供了活性探针来检测和补救这种情况。

在以下Kubernetes官方提供的实例中，创建一个运行基于 k8s.gcr.io/busybox 映像的容器的Pod。在容器生命的前 30 秒，有一个 /tmp/healthy 文件。因此，在前 30 秒内，命令 cat /tmp/healthy 返回一个成功代码。30 秒后， cat /tmp/healthy由于执行失败，返回失败代码。此实例可以推广开来，用户可以替换要执行的反映状态的命令，也可以替换不同的监测状态的命令。

这是 Pod 的配置文件([文件来源](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/))：

```yaml

apiVersion: v1
kind: Pod
metadata:
  labels:
    test: liveness
  name: liveness-exec
spec:
  containers:
  - name: liveness
    image: k8s.gcr.io/busybox
    # 服务启动时执行以下命令
    args: 
    - /bin/sh
    - -c
    - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5
      periodSeconds: 5
```

#### ***报警***

监控系统可以在节点部署监控脚本(exporter)以及核心的时序数据库（例如，[Promethus](https://prometheus.io/), [Ganglia](http://ganglia.sourceforge.net/)等）进行监控数据收集，并通过可视化的系统(例如，[Grafana](https://grafana.com/)等)进行监控报表和可视化的展示。
报警系统（例如，[Alert Manager](https://prometheus.io/docs/alerting/latest/alertmanager/)）可以提前规划好报警规则与阈值，不断监控和分析监控系统中的指标是否违规，如果违规及时发送报警信息或者邮件。尤其对用户提交的作业，深度学习作业容易发生OOM，GPU容易出现阻塞或者ECC错误等问题，对于高频和影响较大的异常需要及时修复与处理。

例如，我们可以设计以下的一些报警规则，并通过系统触发报警让运维人员介入：

1. 负载和性能问题规则：例如，例如磁盘使用率超过一定阈值，网络性能低于一定阈值等
2. 服务健康规则：例如，服务失败报警等
3. 硬件健康规则：例如，节点出现健康问题的报警等

<center> <img src="./img/6/7-6-2-monitor.png" ch="500" width="900" height="600" /></center>
<center>图7-6-2. 监控系统(<a href="https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-packages-monitoring.html">图片来源</a>)</center>

如图所示，一个完整的监控系统如图所示，节点部署监控脚本(例如node-exporter)收集各种性能指标和健康指标，监控指标被存储到时序数据库（例如Promethus）中，报警管理系统周期性查询时序数据库判断是否触发报警，如果触发可以通知接受者（例如通过邮件），同时可视化报表系统也可以查询数据库绘制可视化仪表盘方便管理员监测当前情况。整体的各个系统组件可以通过集群管理系统（例如Kuberenetes）进行部署和运维。

在构建报警系统之初，需要决定以怎样的工具或者方式通知到相应的负责人进行响应和处理。目前有以下常见的多渠道通知的方式，他们各有利弊，一般生产环境可以根据工作时间与非工作时间，以及报警的严重程度综合配置通知软件：

- 电话报警通知：适合紧急处理的故障，电话通知最为直接。特别是在非工作时间发生的重大故障，电话是最快的通知到责任人的方式，所以在候命值班的工程师在责任日需要24小时开机待命。
- 短信报警通知：在短信中可以自行定义通知到的内容包括哪些，但是通知需要订阅短信服务，有一定的成本，不容易被内部系统记录，不容易拉群讨论。
- 即时通讯工具报警通知：报警系统也可以通过直接与IM软件绑定，方便报警转发与讨论，消息也比较及时。例如，Teams，钉钉，企业微信等协作工具，有助于创建群讨论故障，快速协同相关人进行良好协作，共同解决故障。
- 邮件报警通知：适合在工作时间进行报警通知，非工作时间容易错过消息，邮件适合事后分析，追踪与转发事故案例，方便回溯。

## 7.6.3 测试

可以通过 以下几个方面进行系统测试保证平台的常见问题，早发现，早规避，主动出击保证平台软件代码和服务本身的可靠性。

#### ***单元测试***

平台的新增功能模块需要进行单元测试，保证逻辑的正确性。可以选用所使用的模块的开发语言的单元测试库进行单元测试用例的开发。保证函数和模块的正确性。并在回归测试中触发单元测试进行回测。单元测试库一般根据平台开发使用的语言而确定，例如，Python（常用于构建部署脚本，监控等）的[PyUnit](https://wiki.python.org/moin/PyUnit)，Java（常用于构建服务，节点管理器等）的[JUnit](https://junit.org/junit5/)，Golang（构常用于建服务，节点管理器等）的[testing package](https://go.dev/doc/tutorial/add-a-test)，Rust（常用于构建服务，节点管理器等）的[Unit testing](https://doc.rust-lang.org/rust-by-example/testing/unit_testing.html)。目前这些语言的选择一般是根据团队背景和组件需求，在平台与服务中常常用来构建特定的组件。

#### ***集成测试***

由于开源系统的应用越来越广泛，目前很多平台系统或多或少的模块会采用开源系统进行实现和部署，这就造成平台整体的集成测试变得尤为重要。可以在测试集群或者环境中进行集成测试。每次有一定的功能更新在开发分支需要合并到主分支之前，可以触发集成测试，验证没有问题后再进行合并。每次发布前也需要进行集成测试。

#### ***压力测试***

对于平台，可以不间断的自动提交一些测试作业进行巡检，也可以定期进行压力测试检测服务功能的负载能力或硬件的稳定性。例如，[SuperBenchmark](https://github.com/microsoft/superbenchmark)支持对人工智能基础平台和硬件提供，AI工作负载基准测试和分析，提供不同现有硬件之间的综合性能比较，它为原始计算和通信基准测试提供微基准，以及用于测量域感知端到端深度学习工作负载的模型基准。也可以通过其他的深度学习基准测试（例如，[MLPerf](https://github.com/mlperf)等）进行性能与压力测试。

#### ***回归测试***

一旦完成平台新功能开发或者在线热修复，需要进行回归测试保证符合之前系统假设。
回归测试是指修改了已有代码后，重新进行测试以确认修改没有引入新的错误或导致其他代码产生错误。由于当前平台属于在线服务，同时常常使用敏捷开发模式，这样十分容易产生软件缺陷，设计好回归测试的机制，对保证平台的正确性显得尤为重要。

#### ***模糊测试(Fuzzing)与混沌工程*** 

同时也可以考虑使用混沌测试这种缺陷注入机制，主动注入异常，提前修复和增强平台的稳定性。常用的开源混沌工程系统一般是针对通用基础平台（例如代表性的[Chaos Monkey](https://netflix.github.io/chaosmonkey/)），对深度学习和基于Kuberenetes的平台（例如，[Chaos Mesh](https://chaos-mesh.org/)）可以加入新的插件以支持大规模领域特定异常和故障注入。

<center> <img src="./img/6/7-6-1-chaos.png" ch="500" width="1000" height="500" /></center>
<center>图7-6-3. 混沌工程通过模糊测试(Fuzzing)为系统主动注入故障(Failure)，增强系统稳定性。(<a href="">图片来源</a>)</center>


## 7.6.4 平台部署与DevOps

可以通过CI/CD机制，持续集成，持续部署，也就是我们通常所说的[DevOps](https://en.wikipedia.org/wiki/DevOps)。平台本身的各个服务组件也可以打包为Docker镜像，通过Kubernetes等工具部署和管理相应服务。可以通过相关的工具（例如：[Jenkins](https://www.jenkins.io/)），构建CI/CD的流水线，进而保证平台工程时开发新功能或者热修复(Hotfix)后能够自动化走完完整的测试与部署流程，大幅提升开发与部署效率。


## 7.6.5 平台运维

#### ***直接责任人（DRI）与候命（On-Call）机制***

候命（On-Call）机制与之相接近的就是值班，是指平台方为了快速相应平台故障（Fault）或者重大事件（Incident），在某段时间内指定某个人（一般叫做直接责任人（Directly Responsible Individuals））或者某组人随时待命（类似值班）。在故障发生的一瞬间，通过之前的监控与报警系统捕获到问题，之后以邮件、短信、电话等形式通知到负责人，以确保第一时间的响应与处理。

当平台上线部署后，就应该建立支撑的流程和机制。如果使用的监控工具单一，那么集中化就不是最必要的，如何有序处理突发事件更为重要。随着机器越来越多，运维团队人数变多，就逐步需要设置支撑流程和响应机制了。
 - 建立多个梯度，例如，一线、二线，或者设置到第三线候命团队，一线一般为$7 \times 24$小时的候命直接责任人（Directly Responsible Individuals）。$7 \times 24$小时的值班制度不论对于责任人还是整个团队都有较高代价，团队可以通过系统制订排班，实现日、周、月的轮流机制，能让团队责任人经验共享的同时，能够保持一定的休息和工作生活平衡，更加高效的支持平台运维。
 - 二线可以是较为资深工程师，或者是平台研发工程师，他们对系统的疑难杂症更加有经验。
 - 三线可以设置为团队主管，或者汇报线上更高级别的主管。同时可以有外部的厂家，如硬件、云服务等相关服务方。

同时针对不同的告警级别，进行不同的服务等级协议（SLA）的响应（不同的团队可以设置不停的级别和响应及缓解时间，例如，2~5级不同的影响级别），其中按性质有常见的两种比较大的类型：
- 严重事件，如大范围影响平台服务，作业和平台用户使用体验或者数据的，需要及时处理，要求有一定的响应时间要求。如果一定时间内无人响应，将报警需要上升到更高线的响应团队和责任人进行响应。
- 警告事件：影响服务范围和严重程度较低，如作业性能慢，排队时间长等，或者服务资源消耗到一定阈值等，可以通过当天候命的DRI进行处理。



平台也可以通过设置研发工程师轮班成为直接责任人（Directly Responsible Individuals）简称[DRI](https://about.gitlab.com/handbook/people-group/directly-responsible-individuals/)机制，让开发工程师轮岗进行值班与平台问题修复运维，这样不会产生开发与运维职责脱节，责任到位，热修复（Hotfix）也会执行的更快。这也同样体现当前非常流行的DevOps文化，开发与运维的界限变得越来越模糊，这个本质原因是因为锁面对的平台软件常常会部署为服务，相当于本身不是部署到客户现场的客户端软件，相当于服务本身的运行和维护责任还是在平台团队，当前很多在线服务都是这样的一种部署方式，也让整个软件工程中DevOps本身变得越来越重要。

#### ***事件管理***

对平台产生的系统报警和用户提交的问题事件(Incident)，可以通过一定的事件管理进行维护，并制定一定的SLA，保证指定时间内能够介入，缓解与修复，对高优先级的问题需要有相应策略引入更多人员与团队介入。

<center> <img src="./img/6/7-6-3-operation.png" ch="500" width="800" height="300" /></center>
<center>图7-6-4. 平台事件(Incident)管理(<a href="">图片来源</a>)</center>

如上图所示，平台会通过指定事件(Incident)监测，响应，处理与事后分析的机制，进行事件管理，维护平台的稳定性，应对突发事件，同事通过事件本身不断改进系统这样让平台不断演进。

#### ***智能运维***

目前对于过于复杂问题，非结构化运维数据，以及希望数据驱动解决的运维问题，也可以考虑AIOps技术进行智能运维，主动介入与预测，互补于常规运维方法。例如，针对云平台上的磁盘损坏历史信息，工作[NTAM WWW '21](https://www.microsoft.com/en-us/research/publication/ntam-neighborhood-temporal-attention-model-for-disk-failure-prediction-in-cloud-platforms/)通过机器学习方式预测磁盘故障，进而让故障较早的发现让服务进行迁移。智能运维技术适合平台规模较大，且运行过一段时间有数据沉淀的团队使用，这样平台本身积累了大量的数据，有条件通过数据驱动（Data Driven）的方法，在一些场景下解放运维人员的工作。

## 小结与讨论

本章我们主要介绍异构计算集群管理系统的中的开发与运维，当前软件工程逐渐由客户端开发到服务开发，平台本身即服务，我们会面临开发以外，部署，运维，诊断等更为棘手的问题，希望读者在读完本章后意识到基础架构的挑战与复杂性。

## 参考文献
- https://en.wikipedia.org/wiki/Scrum_(software_development)
- https://about.gitlab.com/handbook/people-group/directly-responsible-individuals/
- https://en.wikipedia.org/wiki/DevOps
- https://prometheus.io/docs/alerting/latest/alertmanager/
- https://grafana.com/
- https://prometheus.io/
- http://ganglia.sourceforge.net/
- [Microsoft Online Services incident management](https://www.youtube.com/watch?v=jpTRdV5eZYE)