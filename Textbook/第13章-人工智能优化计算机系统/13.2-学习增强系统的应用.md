<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 13.2 学习增强系统的应用

我们介绍几个学习增强系统的代表性工作。本章包含以下内容：

- [13.2 学习增强系统的应用](#131-学习增强系统的应用)
  - [13.2.1 视频流系统](#1321-视频流系统)
  - [13.2.2 数据库索引](#1322-数据库索引)
  - [13.2.3 系统性能和参数调优](#1323-系统性能和参数调优)
  - [13.2.4 芯片设计](#1324-芯片设计)
  - [参考文献](#参考文献)

## 13.2.1 视频流系统

视频流实现用户可以边下载边播放多媒体数据的功能，像日常生活中的网络视频点播就是视频流的一个主要场景。简单来说，用户不需要下载完整的多媒体数据，而媒体数据流块会依序地下载到本地缓冲并进行实时播放。不难想象，大家常碰到的一个问题就是视频流的播放品质很难一直保持着流畅的高画质，尤其是在网路延迟和带宽不稳定的时候。理想的情况下，视频流应该能随着网路品质来调整传输的码率，以便在不牺牲流畅度的前提下保持着当前网路能支持的最高画质。这类的问题统称为比特率自适应（Adaptive Bit Rate，ABR）。

比特率自适应之所以可以使用强化学习来解决，是因为它可以被看成是一个马尔科夫过程的问题。比特率自适应是根据我们当前的状态来选择下一个流块的码率，它和之前的状态都是不相关的。我们在这章节介绍来自麻省理工学院的工作， Pensieve。Pensieve 的动机即把统比特率自适应的问题，表达成一个强化学习能解决的问题 --- 根据客户端对过去视频流块的反馈，Pensieve 为接下来的视频流块选取最佳的比特率，进而优化体验指标（Quality of Experience，QoE）。一个有趣的观点是，由于对动态的网络进行建模是非常困难的，Pensieve 不希望依赖任何关于网络速率等条件的假设或模型。

Pensieve 的模型训练使用了 Asynchronous Advantage Actor-critic（A3C）。作者指出选择 A3C 的一个原因，在于多个客户端的反馈可同时用于线上训练。Pensieve 包含两个网络模型：一个是 Actor，一个是 Critic。其中 Critic 模型主要是训练代价函数 （Cost function）的，用于辅助 Actor 模型。而 Actor 是决策模型，输出下一个流块应该选择的码率。Actor 模型的输入包括了之前 *k* 个流块的平均网路吞吐量（past chunk throughput），之前 *k* 个流块的下载时间（Past chunk download time），下一个流块可选的码率对应的下载大小（Next chunk sizes），当前缓存的大小（Current buffer size），剩余未下载的流块数量（Number of chunks left），上一个流块的码率（Last chunk bit rate）。

训练时的奖励（Reward）是基于每个流块的 QoE 反馈。Pensieve 对 QoE 的定义是基于之前的一个工作，MPC。基本上，QoE 的设计奖励高码率带来的播放品质的提升，处罚视频播放中的重缓冲和码率切换的平滑性。值得注意的是，播放品质是一个较主观的指标，所以 Pensieve 的作者指出了三种不同的量化的方法。对于不同的方法所计算出来的 QoE 可以用于训练不同的 Actor 和 Critic 网络模型。

从实验结果，作者表示 Pensieve 的表现优于现有的启发式算法。相比于最理想的情况（即知道未来网络状态，做全局优化），Pensieve 达到的 QoE 分数差距在 9.6% - 14.3%。另外，不同的 QoE 可能需要设计不同的启发式算法，而 Pensieve 可基于上面的训练流程从数据中来学习新的模型。最后，作者实验了 Pensieve 的泛化性。实验在三个不同的网路环境下进行视频流播放：波士顿→波士顿 LTE 蜂窝网路，波士顿→波士顿 Wi-Fi，和波士顿→上海的跨国网路。虽然 Pensieve 在不同的环境下达到了不同的性能，整体来说 Pensieve 都能表现得比启发式算法好。

## 13.2.2 数据库索引

索引技术在数据库中扮演着重要角色。索引是一种结构，来对数据库表中一个或多个列（例如人名的姓氏列）的值进行排序。索引的目的在于定位表里的数据，进而提升数据查询的效率。一个例子是范围查询，或返回所有首字母为 "L" 的姓氏值。如果没有索引，这些查询则需要遍历整个数据库表。

主流的索引实现通常是基于平衡树，即 B tree 或 B+ tree。平衡树的叶节点储存着数据的物理位置。由于平衡树的高度可以很小，每次的数据查询只需要几次的树查询。但是这些索引是广义目的的数据结构，没有利用到被索引数据的分布特征。所以，在一些极端情况下，它们可能会表现得较差。比如，当数据键值为从 1 递增到 n，如果使用 b-tree 索引，查询的时间复杂度为平衡树常见的 $O(log\ n)$。但是，理想的情况下，如果利用排序数据键值为位置的特性，则只需要 $O(1)$ 的复杂度。同样，索引的空间复杂度也只需要 $O(1)$，而不是平衡树常见的 $O(n)$。

学习索引（Learned Index）的动机就在于是否能够用模型来学习到数据的分布特征，进一步提升数据查询的效率。学习索引要达到的是学习到一个映射函数，$f(key)$ $\rightarrow$ $pos$。将 $key$ 写成 $x$，$pos$ 写成 $y$，希望学习到一个模型 $f(x)$ 约等于 $y$。在上面的极端例子里，因为 $x$ 是排序过的，所以 $f$ 可以被看成是给数据抽象成 CDF，并学习此 CDF 的模型。

Learned Index 作者首先试的方案是使用训练一个 2 层全连接的神经网络，每层 32 个单元，使用 ReLU 作为激发函数。实验结果表明此模型每秒大概能执行 1250 预测，但这性能远远比不上 B-Tree 索引每秒大约1111111 次的执行。作者指出了几个可能的原因：第一，TensorFlow 的设计在于有效地运行大模型，并不是小模型。第二，不像 B-tree，神经网络所有的单元都必须参与计算。第三，神经网络擅长于学习数据的宏观趋势；如果需要针对性地去学习数据里某一部分的细节，则会带来巨大的空间和运算开销。换句话说，这是一个数据空间变小以后模型的预测能力变差的问题。作者称此问题为 Last Mile。对这三个问题，作者首先提出了 Learning Index Framework（LIF）。LIF 转换 TensorFlow 的模型到一个 C++ 的表达形式，来加速对小模型的推理。另外，作者提出了 Recursive Model Index (RMI) 的递归模型索引来解决 Last Mile 的问题。RMI是一种层级化的架构，包含许多个模型。每一层中的模型都接收键值作为输入，然后据所得到的预测来选择下一层需执行的模型。这流程一直持续到最后一层，然后 RMI 输出在最后一层模型对位置的预测。从概念上来说，每一个模型都可以看作是对键值空间的某一部分负责。而 RMI 在逐层选择的过程中，逐渐降低了预测误差。

实验结果显示出，与 B Tree 相比，学习索引可以更快，消耗的空间也最多可以节省 99%。但是，学习索引目前假设静态工作负载，也就是数据库表只读而不写。虽然如此，学习索引并不是有意图地去替代现有的索引。它提供了另外一种构建索引的思路，而这个思路启发了之后的很多探索工作。

## 13.2.3 系统性能和参数调优

现代系统里有很多的设定与配置参数。透过调整这些设定与配置参数，系统工程师可以改变系统的行为，进而提高系统效能。一个例子是 MySQL 数据库 --- MySQL 有着上百个参数，从缓存相关的（如 `query_cache_size`，`key_cache_block_size`，`read_buffer_size`），磁盘缓式写入相关的（如 `delay_key_write`，`flush_time`），并发线程相关的（如 `innodb_commit_concurrency`），到连接通信的（如 `max_connections`，`net_buffer_length`），等等。有趣的是，许多系统的设定与配置参数的数量有着增长的趋势。在 “*Understanding and Dealing with over-Designed Configuration in System Software*” 这篇论文里，作者对 MySQL 数据库，Apache 网页服务器，和 Hadoop 大数据运行系统做了一个调查来量化这趋势。比如，从 1999 到 2015 年，MySQL 的设定与配置参数从大约 200 到 450。从 1998 到 2014 年，Apache 的设定与配置参数从大约 150 到 600。从 2006 到 2014 年，Hadoop 的设定与配置参数从大约 20 到 180。另外，当我们考虑到一个大型系统可能是由多个子系统组成（例如网页服务器和数据库），这些大型系统的参数数量以指数级地增长。

调整这些设定与配置参数需要工程师理解系统的行为是如何被每一个参数所影响。然而，参数和系统性能的关系是一个高维度的非线性空间，并超出了人的理解能力。所以，对于工程师而言，他们不确定手调的设定与配置是否最优，也很难知道如何有效地找到最优的设定与配置。

系统配置参数调优之所以可以使用机器学习来解决，是因为它可以被看成是一个空间搜索的问题，并能在贝叶斯优化的框架下被解决。简单来说，我们可以先对不同的系统设定与配置，来做性能评测。这些数据的采样可以被看成“系统设定与配置--性能”的空间采样，并能够对此空间建模，进而去推断最有可能使系统效能最高的系统设定与配置。另外，我们也可以继续采集新的系统性能评测来进一步地加强空间建模。贝叶斯优化的优势在于可以用非常少的步数（每一步可以想成用一组性能评测来训练）就能找到比较好的系统配置参数。另一个优势是贝叶斯优化不需要求参数的导数。

接下来，我们从两个角度来探讨影响推断准确率的两个因素：模型的选取和空间的采样。

在模型的选取上，一个常见的做法是假设系统里大多数的配置参数的属性都为连续值，然后把需要探索的空间当作是一个连续空间，并用回归模型来为此连续空间建模。这假设在很多的系统里是成立的。有很多的工作都用高斯过程（Gaussian Process）来作为这里的回归模型。原因是高斯过程模型能为每一个预测提供置信区间（Confidence interval），而这讯息能为我们下面讨论的空间采样给予帮助。但是，高斯过程模型在高维和大规模的训练集情况下，训练和推断的时间会有显著增长。这是因为高斯过程需要为数据点计算之间的距离。虽然 DNN 的训练和推断的时间普遍比高斯过程短，但它无法提供像高斯过程一样的置信区间。 一个有趣的工作是 DNN-GP。DNN-GP 结合了 DNN 模型和高斯过程 --- 先独立训练 基于 DNN 的回归模型，然后把最后 DNN 的 输出层替换成 GP 的模型。根据 DNN-GP 作者的测试，DNN-GP 能达到 接近 DNN 的速度并能提供高斯过程的置信区间。

不光是取决于建模的模型，空间的采样也是非常地重要。由于系统评测可能会有不可忽视的资源和时间开销，空间的采样如果只是基于纯随机采样，不是每一次的采样都能为建模提供有效的信息增益。反之，理想的情况下，每一次的采样都应该能补充之前采样所无法得到的信息。“探索--利用”（Exploration--Exploitation）是一个解决空间采样的思维。简单来说，这思维尝试在探索不确定区域和开采当前已知区域之间进行权衡。前者让我们有机会在还没有充分探索的区域里找寻最优解，以期望获得更高的回报；后者让我们在当前已知的（或有信心的）区域里，来找寻最优解。然而，我们必须思考什么时候应该要在着两个阶段里切换，来尽可能快地找到全局最优解。几个常结合高斯过程的策略包括 maximum probability of improvement (MPI)，expected improvement (EI)，upper confidence bound (UCB)。最后，我们介绍一个为系统配置参数调优的探索--利用策略，Metis。Metis 解决了系统数据上的一个挑战，也就是性能评测可能存在噪声。重复一个性能评测可能会得到不同的结果，尤其是像延迟一样的时间类指标。Metis 在探索和利用的基础之上，也考虑了重采样来保证模型的质量。

## 13.2.4 芯片设计

## 参考文献

- Tianyin Xu, Long Jin, Xuepeng Fan, Yuanyuan Zhou, Shankar Pasupathy, and Rukma Talwadker. 2015. *Hey, You Have Given Me Too Many Knobs!: Understanding and Dealing with Over-Designed Configuration in System Software*. In Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2015). Association for Computing Machinery.
- Hongzi Mao, Ravi Netravali, and Mohammad Alizadeh. 2017. *Neural Adaptive Video Streaming with Pensieve*. In Proceedings of the Conference of the ACM Special Interest Group on Data Communication (SIGCOMM '17). Association for Computing Machinery.
- Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, and Neoklis Polyzotis. 2018. *The Case for Learned Index Structures*. In Proceedings of the 2018 International Conference on Management of Data (SIGMOD '18). Association for Computing Machinery.
- Zhao Lucis Li, Chieh-Jan Mike Liang, Wenjia He, Lianjie Zhu, Wenjun Dai, Jin Jiang, and Guangzhong Sun. 2018. *Metis: Robustly Optimizing Tail Latencies of Cloud Systems*. In Proceedings of the 2018 USENIX Conference on Usenix Annual Technical Conference (ATC '18). USENIX Association.
