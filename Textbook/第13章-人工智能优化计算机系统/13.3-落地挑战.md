# 13.3 落地挑战

- [13.3.1 系统数据](#1331-系统数据)
- [13.3.2 系统模型](#1332-系统模型)
- [13.3.3 系统动态性](#1333-系统动态性)
- [13.3.4 系统正确性](#1334-系统正确性)

虽然学习增强系统的核心是利用机器学习来解决计算机系统的问题，构建和落地一个学习增强系统并不只是选取和整合已有的模型。从过去的科研和产品经验里，我们从 4 个维度来讨论学习增强系统落地的痛点和考虑要素：系统数据，系统模型，系统动态性，系统正确性。

## 13.3.1 系统数据

机器学习的基本思维是从数据中学习。理论上，训练数据如果越多越多元化越正确，则对机器学习越有利。幸运的是，采集系统数据普遍来说并不是一件困难的事，尤其现代的计算机系统普遍有着完善的行为监测机制和精细的日志。执行一次系统评测（benchmarks）能产生对应的数据流。但是，使用这些系统数据来训练模型存在以下的难度。

首先，原始的系统数据的格式对机器学习可能并不友好。不同的监测机制有着不同的格式。而且因为现代系统的接口设计主要是面向开发者的，计算机系统的行为监测机制和精细的日志的设计目标为帮助工程师来处错，很多的系统数据格式并不是机器学习熟悉的“输入--输出”结构格式。一个简单的例子是当操作系统内核崩溃时产生的 kernel crash dump。所以，落地学习增强系统需要能自动化地转化并统一所有的系统数据流。在做这转化时，我们还得注意训练集是由关联系统指令和反馈而组成，但在很多情况下却很难做到正确的关联。一个例子就是系统里的缓冲存储器需要适当地预热，太早采集反馈会得到错误的结果，但太晚采集则会浪费大量的等候时间。

另一个痛点是，因为系统能输出大量的系统数据流，工程师需要判断哪些数据需保留为训练数据集。我们这边用数据库为一个例子 --- 工业界常用的键值数据库 RocksDB 有超过 50 个设定参数，能记录超过 100 性能指标。这问题类似于机器学习的特征选择 (feature selection)。

最后，系统数据可能会有大量的噪声和异常值，而造成模型训练的准确率过低。一个常见的案例是当我们用机器学习模型来预测时间类性能指标，如微服务的请求延迟或网路传输延迟。即使重复相同的系统评测也很有可能采集到不同的延迟数据。这是因为能影响系统延迟的因素很多，不光是系统的设定参数。这些因素可能包含从处理器的缓存策略，操作系统的资源分配策略和线程，虚拟主机上其他租户的负载，网路的环境和负载，到用户的流量，等等。虽然我们可以取多次延迟数据的平均（或最低值）来做模型训练，但重复相同的系统评测有着不可忽视的时间开销。

采集大量的数据需要做大量的系统评测。系统评测可以在线下的测试环境进行，但线下测试环境通常无法完整地复制线上生产环境。如果系统评测在线上生产环境进行，就需要考虑系统评测会不会对实际用户的体验造成影响。所以，一个折中的方法是在一个线上生产环境的隔离区域里进行系统评测。另一个有趣的想法是如何利用机器学习的增量学习和线上学习，来整合线下测试环境和线上生产环境所采集到的训练数据。另外一个系统评测的痛点是时间上的开销使得无法在有效的时间下完成大量的系统评测。一个简单的例子是每一次的系统评测需要等待系统已经完成初始和暖机，并能输出稳定的性能指标。在我们之前的经验，一个完整的系统评测普遍需要至少几分钟。在一些环境比如硬件模拟器，一个完整的系统评测甚至有可能需要几天的时间才能完成。一个有趣的想法是如何使用 Exploration-and-Exploitation 的策略来降低系统评测的次数。Exploration 探索未知空间获取更多信息，而 Exploitation 利用当前已知信息做决策。直觉上，我们应该用长期的全局最优的眼光来选择能带来信息增益最大的系统评测，而不是随机地完成越多的系统评测。

## 13.3.2 系统模型

由于学习增强系统的决策是基于机器学习模型，模型的时间和资源开销是系统运维必须考虑的一部分。我们这里用 Learned Ranker 这个项目来做一个例子。Learned Ranker 作者的目标是利用机器学习来加速规则匹配系统。一个常见的规则匹配系统是网路防火墙。基本上，规则匹配系统的任务在于从所有内建的规则中，找出符合当前输入的字符串。所以，规则匹配的速度大大影响了整个系统的延迟和吞吐量。基于每个网路封包，Learned Ranker 的目的是为防火墙预先排列规则。在最理想的情况下，最有可能匹配上的规则会先被防火墙处理，进而降低防火墙需要为每个封包处理的规则数量。Learned Ranker 的作者尝试用 logistic regression (LR)，DNN，和 RNN。有趣的是虽然 RNN 能更准确得预测最有可能匹配上的规则，但从系统的整体开销的角度来看，提升并不明显。原因在于，相比于 LR 和 DNN， RNN 模型需要更多的资源来做推理。

对于手写的启发式算法，系统工程师可以优化代码和逻辑来降低时间上和资源上的开销。但是，机器学习模型的架构（比如深度神经网络的神经元）并不是系统工程师能轻易读懂和手动优化的。一个有趣的想法是如何使用自动机器学习（AutoML）的技术来帮助系统工程师设计针对场景时间和资源限制的模型，包括模型的架构和超参。

## 13.3.3 系统动态性

现代系统在线上生产环境有着强烈的动态性，而这些动态性使得系统的行为随着时间而改变。这些动态性来自于几个因素。第一个因素是系统的负载。比如，搜索引擎随着用户的数量和搜索关键字而变；视频流系统的负载随着视频的选择和解析度而变；数据库的负载随着读写请求和比例而变。第二个因素是系统的部署。一个典型的例子是微服务的架构。由于微服务的架构隔离了每个系统的子服务，这些子服务可以被像 Kubernetes 这类的容器管理平台来随着系统的负载而自动扩容。扩容改变了子服务的数量和部署，也因此改变了系统的特性和性能。第三个因素是系统的环境。这包括软件和硬件的升级，多租户伺服器上的其他租户的资源使用，等等。不难理解，在这些情况下，机器学习模型对于任务的一些假设会随着时间而不成立。但有趣的是，这些模型的假设不仅仅在数据分布，也反应在模型的架构。我们下面

系统动态性意味着机器学习模型对于任务的一些假设会随着时间而不成立。不难理解，学习增强系统的机器学习模型必须要能自适应，以便做出对的决策。比如，如果系统的当前行为是模型训练时不曾见过的，学习增强系统需要训练机器学习模型。一个有趣的想法是整合增量学习和线上学习，但这些方法存在一定的限制。比如在上面自动扩容的例子里，每一次的扩容不仅仅是需要重新训练模型，而是需要重新设计模型的架构。另外，线上学习有灾难性遗忘 （catastrophic forgetting）的问题 --- 即神经网络在新数据上训练后，权重发生变化，导致神经网络遗忘旧数据上学习到的知识。。虽然一种解决灾难性遗忘的办法是保存历史数据做训练，这造成了储存空间的开销。有些数据甚至因为隐私的原因，不能被长久保存。

有趣的是，系统动态性对模型的假设改变不仅仅是在数据分布上，也可能反应在模型的架构上。比如，如果微服务的应用被扩容到之前两倍的大小，这改变了集群里节点的数量。所以，模型的输入维度和架构也需要做相对应的改动，来接受增加的子服务。反之，当微服务的应用的部署规模被缩小时，我们也需要新模型。然而，痛点在于训练新模型需要时间和资源。

## 13.3.4 系统正确性

机器学习的预测和推理自身带有不确定性。当学习增强系统的决策是基于不确定的模型预测，所做的系统决策很有可能会是不合理的（或甚至太激进）。比如，当模型无法准确地预测一个系统的性能指标，学习增强系统则无法保证参数调优的效果。上线一组不适当的参数可能会造成系统的性能大幅度地下降，甚至系统崩溃。另一个例子是自动驾驶汽车。我们要帮助汽车了解在行驶过程中所遇到的新型物体，如骑自行车的人和动物等等。但是，要做到这一点，我们需要了解什么时候汽车对于它看到的对象不能确定，以及如何最好地解决这种不确定性。然而，机器学习模型不像手写的启发式算法，模型的架构（比如深度神经网络的神经元）并不是系统工程师能轻易读懂的。即使是机器学习专家，也很难知道模型何时不确定以及如何计算不确定性。另外，由于机器学习模型架构有别于代码，传统的软件测试方法很难适用于学习增强系统。
所以，如何降低机器学习不确定性对系统正确性的影响是一个至关重要的挑战。

现阶段，解决这问题的方法有三大思路。第一种思路是降低模型的不确定性 --- 尽可能地采集越多的数据来训练和设计模型，也尽可能地采集模型有可能预测错误的输入。但是，这思路不能保证模型的不确定性。对于有些计算机系统，这思路需要大量的时间和资源开销，因为牵扯到我们前面讨论过的系统数据问题。第二种思路是使模型有能力量化，解释，和反馈一个推理的不确定性。一个简单的例子是高斯过程模型 （Gaussian process） --- 高斯过程是一种概率模型，无论是回归或者分类预测都能以高斯分布标准差的方式，给出预测置信区间估计 （confidence interval）。基本上，在已知的数据点周围，置信区间较小（对于预测的信心越大），离已知点越远，置信区间越大（对于预测的信心越小）。基于置信区间估计，学习增强系统可以间接地评估一个决策。对于信心较小的预测，学习增强系统可以用人机回圈的方式来得到专家的帮助。但是，高斯过程模型之外，目前大多数的模型都无法提供预测置信区间估计。第三种思路是利用手写的规则来线上评估模型驱动的决策。在这思路下，工程师把已知的系统错误设定写成规则。如果一个模型驱动的决策符合任意一条规则，则拦截其决策。一个例子是自动驾驶汽车。

最后，我们想讨论因为当决策太激进而影响系统正确性的可能性。这常发生在利用机器学习来驱动系统行为调整的场景，比如系统参数的调优。激进的决策可以是因为计算机系统的行为太频繁地或太大幅度地被调整。这两种情况都有可能造成系统的不稳定。当计算机系统的行为太频繁地被调整，计算机系统没有足够的时间来达到稳定的状态。理论上，这时的系统反馈还不能正确地表达上个行为调整的结果，所以并不应该作为下个行为调整的依据。一个例子是在扩容微服务或参数调优之后，微服务需要一段时间来清空之前堆积的请求。另外，当计算机系统的行为太大幅度地被调整（例如太多的系统设定参数在同一时间被调整），计算机系统也可能需要一段时间来达到稳定的状态。
